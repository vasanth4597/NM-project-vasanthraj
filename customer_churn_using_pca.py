# -*- coding: utf-8 -*-
"""CUSTOMER CHURN USING PCA.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1AlrqfnaYnt5KHMslw9SrY37RrrecqDA9
"""

import pandas as pd
import numpy as np

from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, roc_auc_score
from sklearn.preprocessing import StandardScaler, LabelEncoder

df=pd.read_csv("/content/customer_churn_.csv")
df.columns

df.drop(columns=['customerID'],inplace=True)
df.isnull().sum()

df.dtypes

df.dtypes

df.shape

df.isnull().sum()

df.duplicated().sum()

df.drop_duplicates(inplace = True)

dfob=df.select_dtypes('object').columns

le=LabelEncoder()
for col in dfob:
  df[col]=le.fit_transform(df[col])
le

df['Churn'].value_counts()

X=df.drop(columns=['Churn'])
Y=df['Churn']

X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, stratify = Y, random_state = 100 )

scaler = StandardScaler()

X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

log_reg = LogisticRegression()
log_reg.fit(X_train_scaled, y_train)

y_pred = log_reg.predict(X_test_scaled)
roc_auc_score(y_test, y_pred)

from sklearn.decomposition import PCA

pca = PCA(n_components = 0.95)

X_train_pca = pca.fit_transform(X_train_scaled)
X_test_pca = pca.transform(X_test_scaled)
X_train_pca.shape

pd.DataFrame(X_train_pca)

log_reg2 = LogisticRegression()
log_reg2.fit(X_train_pca, y_train)

y_pred_2 = log_reg2.predict(X_test_pca)
roc_auc_score(y_test, y_pred_2)

from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
lda = LinearDiscriminantAnalysis()

X_train_lda = lda.fit_transform(X_train_scaled, y_train)
X_test_lda = lda.transform(X_test_scaled)

log_reg_3 = LogisticRegression()
log_reg_3.fit(X_train_lda, y_train)

y_pred_3 = log_reg_3.predict(X_test_lda)
roc_auc_score(y_test, y_pred_3)

from sklearn.tree import DecisionTreeClassifier
Dt=DecisionTreeClassifier()
model_dt=Dt.fit(X_train_pca,y_train)
Y_pred_dt=model_dt.predict(X_test_pca)

roc_auc_score(y_test, Y_pred_dt)

from sklearn.ensemble import RandomForestClassifier
rf=RandomForestClassifier(class_weight='balanced')
rf.fit(X_train_lda,y_train)
y_pred_rf=rf.predict(X_test_lda)
accuracy_score(y_test,y_pred_rf)*100

from sklearn.metrics import classification_report, confusion_matrix

print(confusion_matrix(y_test, y_pred_rf))
print(classification_report(y_test, y_pred_rf))

rf = RandomForestClassifier(class_weight='balanced', random_state=42)
rf.fit(X_train_scaled, y_train)
from imblearn.over_sampling import SMOTE
sm = SMOTE(random_state=42)
X_resampled, y_resampled = sm.fit_resample(X_train_scaled, y_train)
rf.fit(X_resampled, y_resampled)
y_pred = rf.predict(X_test_scaled)

from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
print(confusion_matrix(y_test, y_pred))
print(classification_report(y_test, y_pred))
print("Accuracy:", accuracy_score(y_test, y_pred) * 100)

from sklearn.model_selection import RandomizedSearchCV
from sklearn.ensemble import RandomForestClassifier
from scipy.stats import randint

# Define parameter grid
param_dist = {
    'n_estimators': randint(100, 300),
    'max_depth': [None, 10, 20, 30, 40],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4],
    'max_features': ['sqrt', 'log2', None]
}

# Initialize classifier
rf = RandomForestClassifier(random_state=42)

# Random search
random_search = RandomizedSearchCV(
    estimator=rf,
    param_distributions=param_dist,
    n_iter=50,  # try 50 combinations
    scoring='f1',  # target churn class performance
    cv=5,
    verbose=1,
    n_jobs=-1
)

# Use the SMOTE-resampled training data
random_search.fit(X_resampled, y_resampled)

# Best model
best_rf = random_search.best_estimator_

y_pred = best_rf.predict(X_test_scaled)

from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
print(confusion_matrix(y_test, y_pred))
print(classification_report(y_test, y_pred))
print("Accuracy:", accuracy_score(y_test, y_pred) * 100)